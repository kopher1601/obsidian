## 처리량과 응답 시간

성능이 저하되면 가장 눈에 띄는 현상은 결과가 늦게 표시되는 것이다.

서버 성능과 관련 있는 중요한 지표를 2가지 꼽자면 응답 시간과 처리량을 들 수 있다.

### 응답 시간

응답 시간은 사용자의 요청을 처리하는 데 걸리는 시간을 의미한다.
클라이언트(앱이나 브라우저)가 서버로 요청을 보내는 과정은 크게 2 단계로 이루어진다.

- **서버에 연결** : TCP 를 이용해서 서버에 연결한다잉
- **데이터 전송** : 정해진 규칙에 따라 데이터를 서버에 전송한다. 예를 들어 HTTP 프로토콜에 따라 POST 방식으로 JSON 데이터를 보낼 수 있다

서버는 로직을 실행한 다음에 응답 데이터를 클라이언트에 전송한다. 응답 데이터를 전송할 때는 API 요청 과정에서 서버와 연결된 소켓을 이용한다.

응답 시간은 다음과 같이 두 가지로 나누어 측정하기도 한다

- **TTFB(Time to First Byte)** : 응답 데이터 중 첫 번째 바이트가 도착할 때까지 걸린 시간
- **TTLB(Time to Last Byte)** : 응답 데이터의 마지막 바이트가 도착할 때까지 걸린 시간

응답 데이터의 크기가 작다면 TTFB 와 TTLB 의 차이가 크지 않다. 하지만 파일 다운로드처럼 전송할 데이터가 크거나 네트워크 속도가 느리면 TTFB 와 TTLB 의 차이가 커질 수 있다.

서버 개발자는 주로 서버의 처리 시간을 확인한다.

- 로직 수행 (if, for 등)
- DB 연동 (sql 실행 등)
- 외부 API 연동
- 응답 데이터 생성(전송)

이 중에서도 DB 연동과 외부 API 연동이 큰 비중을 차지한다.

응답 시간의 증가는 사용자 이탈로 이어질 수 있다. 이를 방지하려면 다음 2가지 방법을 고려해야 한다.

- 서버가 동시에 처리할 수 있는 요청 수를 늘려 대기 시간 줄이기
- 처리 시간 자체를 줄여 대기 시간 줄이기

두 방법을 적용하면 TPS 를 높일 수 있다.

성능을 개선하려면 먼저 현재 서버의 TPS 와 응답 시간을 알아야 한다. 막연히 성능이 느리다고 말하면서 이것저것 시도하면 안 된다. 트래픽이 많은 시간대의 TPS 와 응답 시간이 얼마인지 측정하고, 이 결과를 바탕으로 목표 TPS 와 응답 시간을 설정하고 효과적인 성능 개선안을 도출해야 한다.

## 서버 성능 개선 기초
### 병목 지점
성능 문제는 사용자가 늘면서 점차 나타난다. 트래픽이 늘고 데이터가 쌓이면서 간혈적으로 응답 시간이 느려지는 현상이 발생한다.

트래픽이 증가하면서 성능 문제가 발생하는 주된 이뉴는 시스템이 수용할 수 있는 최대 TPS 를 초과하는 트래픽이 유입되기 떄문이다. 시스템이 제공할 수 있는 최대 TPS 를 높이지 않으면 증가하는 트래픽을 적절히 처리할 수 없다.

TPS 를 높이려면 먼저 성능 문제가 발생하는 지점을 찾아야 한다. 문제 지점을 찾는 간닿나 방법은 처리 시간이 오래 걸리는 작업을 식별하는 것이다.

- 경험상 성능 문제는 주로 DB 나 외부 API 와 연동하는 과정에서 발생했다

### 수직 확장과 수평 확장
**수직확장(scale-up)**
급한 불을 끄는 방법 중 하나는 수직 확장(scale-up)을 하는 것이다. 수직 확장은 CPU, 메모리, 디스크 등의 자원을 증가시키는 것을 말한다.
![[Screenshot 2025-10-22 at 17.49.13.png]]

수직 확장은 즉각적인 효과를 바로 얻을 수 있지만 트래픽이 지속해서 증가하면 언젠가 결국 또다시 성능 문제가 발생한다. 그때마다 수직 확장을 반복할 수는 없다.

**수평 확장(sacle-out)**
![[Screenshot 2025-10-22 at 17.49.31.png]]
서버를 늘리는 방법을 수평 확장(scale-out)이라고 한다.

TPS 를 높이기 위해 무턱대고 서버를 추가해서는 안 된다. 실제 병목 지점이 어디인지 파악하는 게 중요하다. DB 에서 성능 문제가 발생하고 있는데 서버를 추가로 투입하면 불에 기름을 붙는 격이다. DB 문제가 있는 상황에서 DB 를 사용하는 서버를 더 늘리면 DB 에 가해지는 부하가 더 커지고 성능 문제는 더 악화된다. 외부 API 의 성능이 문제인 경우도 마찬가지다.

### DB 커넥션 풀
네트워크에서 DB 를 연결하고 종료하는 시간은 전체 응답시간에 영향을 준다. 응답 시간이 길어지면 전체 처리량은 떨어진다. 트래픽이 증가하면 이러한 현상은 더 두드러진다. 매 요청마다 DB 를 연결하고 종료하면 트래픽이 증가할 때 급격하게 처리량이 떨어지기도 한다.

이런 문제를 피하기 위해 DB 커넥션 풀을 사용한다. DB 커넥션 풀은 DB 에 연결된 커넥션을 미리 생성해서 보관한다.

커넥션 풀은 다양한 설정을 제공한다. 그중 중요한 설정은 다음과 같다

- 커넥션 풀 크기(또는 최소 크기, 최대 크기)
- 풀에 커넥션이 없을 때 커넥션을 구할 때까지 대기할 시간
- 커넥션의 유지 시간(최대 유휴 시간, 최대 유지 시간)

### 커넥션 풀 크기
[[커넥션 풀]] 크기는 커넥션 풀에 미리 생성해둘 커넥션 개수를 지정하는 설정이다. 커넥션 풀 크기는 커넥션 풀 설정에서 가장 중요하다.

풀에서 커넥션을 얻기 위해 대기하는 시간을 줄이려면 전체 응답 시간과 TPS 를 고려하여 커넥션 풀 크기를 지정해야 한다.

커넥션 풀 크기를 늘리면 처리량을 높일 수 있다. 그러나 풀 크기를 무턱대고 늘리면 안된다. DB 상태를 보고 늘려야 한다.

### 커넥션 대기 시간
대기 시간이란 풀에 사용할 수 있는 커넥션이 없을 때 커넥션을 얻기 위해 기다릴 수 있는 최대 시간을 의미한다. 지정된 대기 시간 안에 커넥션을 구하지 못하면 DB 연결 실패 에러가 발생 한다.

커넥션을 얻기 위해 대기하는 시간만큼 응답 시간도 길어진다. 트래픽의 양이나 서비스의 특성에 따라 차이는 있지만 보통의 경우라면 0.5초에서 3초 이내로 지정하자.

> HikariCP의 기본 대기 시간 : 30초

대기 시간을 짧게 설정하면 커넥션 풀이 모두 사용중일 때 빠르게 '일시적 오류'와 같은 에러 응답을 사용자에게 보여줄 수 있다. 에러를 응답하는게 부정적으로 보일수도 있다. 하지만 대기 시간 때문에 긴 시간 동안 무응답 상태로 유지되는 것보다는 빠르게 에러를 반환하는 것이 더 낫다. 커넥션을 얻지 못했을 때 빠르게 에러를 응답해야 서버의 부하가 증가하는 것도 방지할 수 있다. 이처럼 대기 시간을 짧게 설정하면 서버 부하를 일정 수준으로 유지할 수 있으며 서버를 안정적으로 운영하는 데 도움이 된다.

### 최대 유휴 시간, 유효성 검사, 최대 유지 시간
커넥션이 사용되지 않는 시간이 길어지면 연결이 끈길 수 있다.

MySQL과 같은 DB 는 클라이언트와 일정 시간 동안 상호작용이 없으면 자동으로 연결을 끊는 기능을 제공한다.  이때 DB 와의 연결이 끊긴 커넥션을 사용하면 에러가 발생한다. 이러한 연결 끊김으로 인해 발생하는 에러를 방지하기 위해 커넥션 풀은 다음 2가지 기능을 제공한다.
- 최대 유휴 시간 지정
- 유효성 검사 지원

**최대 유휴 시간**은 사용되지 않는 커넥션을 풀에 유지할 수 있는 최대 시간을 의미한다. 최대 유휴 시간을 30분으로 설정하면 30분 이상 사용되지 않은 커넥션은 종료되어 풀에서 제거된다.
이 시간을 DB 에 설정된 비활성화 유지 시간보다 짧게 설정하면, DB 가 연결을 끊기 전에 풀에서 커넥션을 제거할 수 있다.

**유효성 검사**는 커넥션이 정상적으로 사용할 수 있는 상태인지 여부를 확인하는 절차이다. 커넥션 풀의 구현 방식에 따라 커넥션을 풀에서 가져올 때 유효성을 검사하거나 주기적으로 검사할 수 있다. 이 과정을 통해 연결이 유효하지 않은 커넥션을 식별하고 풀에서 제거할 수 있다.

**최대 유지 시간**은 커넥션이 생성된 시점부터 최대 설정된 시간까지만 유지된다. 설정 시간이 지나면 커넥션이 유효하더라도 커넥션을 닫고 풀에서 제거된다.

> 최대 유휴 시간과 최대 유지 시간을 무한대로 설정하지 않는 것이 좋다.

### 서버 캐시
DB 서버를 확장하지 않고도 응답 시간과 처리량을 개선하고 싶다면 캐시(cache) 사용을 고려할 수 있다. 캐시는 일종의 (키, 값) 쌍을 저장하는 Map 과 같은 형태의 데이터 저장소다.
캐시에 데이터를 저장해두면 동일한 데이터를 요청할 때 DB 가 아닌 캐시에서 데이터를 읽어와 응답할 수 있다. 

일반적으로 캐시에서 데이터를 읽는 속도가 DB 보다 빠르기 때문에 자주 조회되는 데이터를 캐시에 보관하면 응답 시간을 줄일 수 있다.
![[Screenshot 2025-10-22 at 19.17.58.png]]

### 적중률과 삭제 규칙

> 적중률(hit rate) = 캐시에 존재한 건수 / 캐시에서 조회를 시도한 건수

적중률이 높을수록 DB 와의 연동이 줄어들고 곧 응답 시간 감소, 처리량 증가, DB 부하 감소로 이어진다.
적중률을 높이는 가장 간단한 방법은 캐시에 최대한 많은 데이터를 저장하는 것이다. 하지만 캐시에 모든 데이터를 무작정 저장할 수는 없다. 캐시는 메모리 자원을 사용하기 떄문이다. 사용할 수 있는 메모리 용량은 한계가 있기에 캐시에 저장할 수 있는 데이터 개수나 크기도 제한된다.

### 로컬 캐시와 리모트 캐시
서버가 사용하는 캐시에는 크게 두 종류가 있다. 첫 번째는 로컬(local)캐시다. 로컬 캐시는 **서버 프로세스와 동일한 메모리를 캐시 저장소로 사용**한다.

두 번째는 리모트(remote)캐시다. 리모트 캐시는 별도 프로세스를 캐시 저장소로 사용한다.
![[Screenshot 2025-10-23 at 15.17.43.png]]
캐시에 보관할 데이터 규모가 작교 변경 빈도가 매우 낮다면 로컬 캐시로 충분하다. 반면에 데이터 규모가 크다면 리모트 캐시를 사용해야 한다. 또한 배포 빈도가 높은 서비스라면 리모트 캐시 사용을 적극적으로 고려하자.

### 캐시 사전 적재
트래픽이 순간적으로 급증하는 패턴을 보인다면 캐시에 데이터를 미리 저장하는 것도 고려할 필요가 있다.

### 캐시 무효화
캐시를 사용할 때 반드시 신경 써야 할 점은 유효하지 않은 데이터를 적절한 시점에 캐시에서 삭제하는 것이다. 캐시에 보관된 원본이 바뀌면, 그에 맞춰 캐시에 보관된 데이터도 함께 변경하거나 삭제해야 한다. 원본이 변경됐는데 캐시에 저장된 데이터가 갱신되지 않으면 사용자는 오래된 잘못된 정보를 확인하게 되는 문제가 발생할 수 있다.
### 가비지 컬렉터와 메모리 사용
메모리를 많이 사용하고 생성된 객체가 많을수록 사용하지 않는 객체를 찾는 데 시간이 오래 걸린다. GC(Garbage Collection) 알고리즘과 메모리 사용 패턴에 따라 차이가 있지만 사용하는 메모리양과 객체 수가 많을수록 GC 실행 시간은 길어진다. 
반대로 메모리 사용을 줄이면 GC 시간도 줄어들 가능성이 높아진다.

한 번에 대량으로 객체를 생성하는 것도 주의해야 한다. 대량으로 객체가 생성되는 것을 방지하려면 조회 범위를 제한해야 한다. 

파일 다운로드와 같은 기능을 구현할 때는 스트림을 활용한다. 파일 데이터를 한꺼번에 메모리에 로딩한 후에 응답하는 방식은 피해야 한다. 파일 크기와 동시 사용자수에 따라 메모리 사용량이 급증할 수 있기 때문이다.

**파일을 한 번에 메모리에 로딩하는 코드**
```java
byte[] bytes = Files.readAllBytes(Path.of("path"));
out.write(bytes);
```
이 코드는 30MB 크기의 파일을 100명이 동시에 다운로드 하면 약 3GB의 메모리가 필요하게 된다.

**스트림을 이용한 코드**
```java
InputStream is = Files.newInputStream(Path.of("path"));
byte[] buffer = new byte[8192]; // 8KB 메모리
int read;
while((read = is.read(buffer, 0, 8192)) >= 0) {
	out.write(buffer, 0, read);
}  
// is.transferTo(out)와 동일 코드
```
이 코드는 파일을 한 번에 읽지 않고 8KB 씩 끊어서 읽는다. 동시에 100 명이 다운로드를 요청하더라도 필요한 메모리는 800KB에 불과하다.

### 응답 데이터 압축
응답 시간에는 데이터 전송 시간이 포함된다. 이 전송 시간은 2가지 요인에 영향을 받는다.
- 네트워크 속도
- 전송 데이터 크기
사용자의 네트워크 속도가 느리면 응답 시간이 길어진다. 하나의 무선 공유기에 너무 많은 사용자가 붙었을 때 웹사이트가 늦게 뜨는 것과 같다. 전송할 데이터의 크기가 커도 응답 시간이 길어진다. 

서버는 사용자의 네트워크 속도를 제어할 수 없지만 전송하는 데이터 크기는 제어할 수 있다. 이때 사용할 수 있는 방법이 바로 응답 데이터를 압축해서 전송하는 것이다. 실제로 테스트 데이터를 gzip 으로 압축하면 70% 이상 크기를 줄일 수 있으며 데이터 전송 크기가 줄어든 만큼 전송 시간도 빨라진다. 즉, 응답 시간이 짧아진다.

> 아파치나 Nginx 와 같은 웹 서버는 압축 기능을 제공하고 있으므로 약간의 설정만 추가하면 즉시 효과를 볼 수 있다.

> Accept-Encoding 요청 헤더와 Content-Encoding 응답헤더
> 웹 브라우저나 HTTP 클라이언트는 `Accept-Encoding` 헤더를 통해 서버에 처리할 수 있는 압축 알고리즘을 알린다.
> - `Accept-Encoding: gzip, deflate`

응답 데이터를 압축할 때는 다음 사항을 고려하자.
- html, css, js, json 과 같은 테스트 형식의 응답은 압축률이 높아 효과적이다. 반면 jpeg 이미지나 zip 파일 처럼 이미 압축한 데이터에는 다시 압축해도 효과가 없다. 따라서 모든 응답에 압축을 적용하지 말고 테스트 형식의 데이터에 압축을 적용하자
- 웹 서버에서 압축을 적용했더라도 방화벽이 이를 해제해 응답할 수 있다. 즉, 웹 서버에 압축 설정을 적용했음에도 실제 응답 데이터가 압축되지 않았다면 방화벽 설정도 확인해야 한다

### 정적 자원과 브라우저 캐시
서버가 전송하는 트래픽을 줄이면서 브라우저가 더 빠르게 화면을 표시할 수 있는 방법이 있다. 바로 클라이언트 캐시를 활용하는 것이다. HTTP 프로토콜에서는 데이터를 응답할 때 `Cache-Control` 이나 `Expires` 헤더를 이용해 클라이언트가 응답 데이터를 일정 시간 동안 저장해둘 수 있도록 설정할 수 있다. 

> `Cache-Control: max-age=60`

브라우저는 같은 url 주소로부터 a.png 파일을 다운로드하면, 해당 파일을 로컬 캐시(메모리나 디스크)에 보관한다. 이후 같은 주소를 60 초 이내에 다시 요청하면 서버에 요청을 보내지 않고 로컬에 보관한 데이터를 사용해서 표시한다.

### 정적 자원과 CDN
브라우저 캐시를 사용하면 네트워크 트래픽을 줄일 수 있지만 여전히 문제가 발생할 수 있다. 브라우저 캐시는 브라우저 단위로 동작하기 때문에 동시에 많은 사용자가 접속하면 순간적으로 많은 양의 이미지, JS, CSS 를 전송하게 된다. 이로 인해 빠르게 네트워크가 포화되어 응답 시간이 급격히 느려진다. 

이런 문제를 해결하는 방법 중 하나는 CDN(Content Delivery Network; 컨텐츠 전송 네트워크)을 사용하는 것이다. 
![[Screenshot 2025-10-23 at 16.55.16.png]]
사용자는 CDN 이 제공하는 URL 을 통해 콘텐츠에 접근한다. CDN 서버에 요청한 콘텐츠가 없으면 오리진 서버에서 읽어와 제공한다. 오리진 서버에서 읽어온 콘텐츠는 캐시에 보관한다.

### 대기 처리
짧은 시간 동안 폭증하는 트래픽은 어떻게 처리해야 할까 ?

**서버를 미리 증설하는 방법**
클라우드를 사용하고 있다면 서버를 쉽게 증설할 수 있다. 하지만 서버만 증설한다고 끝나지 않는다. DB 성능도 문제가 된다. 트래픽은 DB 에도 영향을 미치기 때문이다.

**수용할 수 있는 수준의 트래픽만 받아들이고 나머지는 대기 처리하는 방법**
트래픽이 순간적으로 증가할 때 동시에 수용할 사용자 수를 제한하고 나머지 사용자를 대기 처리하면 다음의 이점을 얻을 수 있다.
- 서버를 증설하지 않고도 서비스를 안정적으로 제공할 수 있다
- 사용자의 지속적인 새로 고침으로 인한 트래픽 폭증도 방지할 수 있다. 사용자는 새로 고침할 경우 순번이 뒤로 밀리기 때문에 불필요한 새로 고침을 자제하게 된다

