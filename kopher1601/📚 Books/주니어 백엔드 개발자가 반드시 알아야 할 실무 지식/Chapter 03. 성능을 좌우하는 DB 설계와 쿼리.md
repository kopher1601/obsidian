## 성능에 핵심인 DB
DB 성능은 연동하는 모든 서버 성능에 영향을 준다. [[Full Scan]] 등으로 쿼리 실행 시간이 길어지면서 전체 서비스가 느려지는 성능 문제는 흔히 발생하는 문제다. 하지만 DB 자체가 문제인 상황은 많지 않았다. 오히려 DB 를 잘못 사용해서 발생한 문제가 더 많았다.
![[Screenshot 2025-10-23 at 17.08.24.png]]

## 조회 트래픽을 고려한 인덱스 설계
DB 테이블을 설계할 때는 조회 기능과 트래픽 규모를 고려해야 한다. 이를 고려하지 않으면 성능에 심각한 문제가 발생할 수 있다. 
- TPS 가 적은 상황에서 조회 성능을 올리기 위해 category 컬럼에 인덱스를 추가할 필요는 없다. 데이터양이 적고 동시 접속자도 매우 적기 때문에 테이블을 풀 스캔하더라도 성능 문제가 발생하지 않기 때문이다
반면에 인기 커뮤니티 사이트라면 많은 사용자가 동시에 게시글 목록을 조회하게 되면 다수의 풀 스캔이 발생하고 이로 인해 성능저하가 발생할 수 있다.

풀 스캔이 발생하지 않도록 하려면 **조회 패턴을 기준으로 인덱스를 설계**해야 한다.
게시판의 경우, **카테고리별로 게시글 목록을 조회하는 패턴**이 존재하므로 category 컬럼에 인덱스를 추가해서 조회 성능을 개선할 수 있다.

> `like %검색어$` 는 풀 스캔을 유발할 수 있다. MySQL 의 `FULLTEXT` 인덱스 사용을 고려하자

### 단일 인덱스와 복합 인덱스
```sql
select * from activityLog where userId = 123 and activityDate = '2024-07-31' order by activityDatetime desc
```
위 SQL 쿼리는 현재 인덱스가 전혀 없는 테이블에서 실행될 때 **심각한 성능 문제**를 일으킬 수 있다.
성능 문제를 해결하려면 `userId` 를 포함한 [[인덱스]]가 필요하다. 여기서 고민할 점은 `activityDate` 를 포함하느냐 하지 않느냐에 대한 것이다.
- 단일 인덱스 : `userId` 만 인덱스로 사용
- 복합 인덱스 : `(userId, activityDate)` 를 인덱스로 사용
사용자당 가질 수 있는 데이터가 얼마나 될지 가늠해보면 어떤 인덱스를 사용해야 할지 판단하는 데 도움이 된다.

### 선택도를 고려한 인덱스 컬럼 선택
인덱스를 생성할 때는 선택도(selectivty)가 높은 컬럼을 골라야 한다. 선택도는 인덱스에서 특정 컬럼의 _고유한_ 값 비율을 나타낸다. 선택도가 높으면 해당 컬럼에 고유한 값이 많다는 뜻이며, 선택도가 낮으면 고유한 값이 적다는 뜻이다. 선택도가 높을수록 인덱스를 이용한 조회 효율이 높아진다.
```sql
create table member (
	memberId int not null primary key,
	gender char(1),
	...
)
```
gender 컬럼이 M, F, N 의 3개 값 중 하나를 갖고, gender 컬럼을 인덱스로 사용한다고 하자. 전ㄴ체 회원 데이터 중에서 M이 50만 개, F가 50만 개, N이 천 개일 때 다음 쿼리를 실행하면 여전히 50만 개의 데이터를 확인해야 한다. 즉, 선택도가 낮아 인덱스 효율이 떨어진다.
```sql
select * from member
where gender = 'F' and birthyear = 1900;
```

### 커버링 인덱스 활용하기
커버링 인덱스는 **특정 쿼리를 실행하는 데 필요한 컬럼을 모두 포함하는 인덱스**를 말한다. 커버링 인덱스를 사용하면 쿼리 실행 효율을 높일 수 있다.
```sql
select activtyDate, activityType
from activtyLog
where activityDate = '2024-07-31' and aictivtyType = 'VISIT';
```

### 인덱스는 필요한 만큼만 만들기
효과가 적은 인덱스를 추가하면 오히려 성능이 나빠질 수 있다. 인덱스는 조회 속도를 빠르게 해주지만 데이터 추가, 변경, 삭제 시에는 인덱스 관리에 따른 비용(시간)이 추가되기 때문이다. 또한 인덱스 자체도 데이터이기 때문에 인덱스가 많아질수록 메모리와 디스크 사용량도 함께 증가한다.

새로 추가할 쿼리가 기존에 존재하는 인덱스를 사용하지 않을 때는 요구사항을 일부 변경할 수 있는지 검토해보자. 작은 변경으로도 인덱스를 활용할 수 있기 때문이다.
```sql
create table reservation (
	id bigint not null primary key,
	name varchar(30) not null,
	reserveDate date not null,
	...
);
create index idxRdate ON reservation (reserveDate);
```
기존 요구 사항을 반영한 쿼리
```sql
select * from reservation
where name = '홍길동'
order by regDt desc;
```
reservation 테이블은 name 컬럼을 인덱스로 갖고 있지 않으므로 위 쿼리를 실행하면 풀 스캔이 발생한다. 풀 스캔을 방지하기 위해 name 컬럼을 인덱스로 추가할 수도 있지만, 요구 사항을 일부 변경하면 인덱스를 추가하지 않아도 된다.
```sql
select * from reservation
where reserveDate = '2024-08-09' and name = '홍길동';
```

## 몇 가지 조회 성능 개선 방법
인덱스가 아니어도 조회 성능을 개선할 방법이 존재한다.
### 미리 집계하기
count, sum 과 같은 집계 쿼리를 조회 시점에 실행하면서 발생하는 성능 문제를 제거하는 방법은 간단하다. 집계 데이터를 미리 계산해서 별도 컬럼에 저장하면 된다.

### 페이지 기준 목록 조회 대신 ID 기준 목록 조회 방식 사용하기
오프셋을 사용하면 지정한 오프셋만큼 데이터를 세는 시간이 필요하다.
지정한 오프셋으로 이동하기 위해 데이터를 세는 시간을 줄이는 방법은 특정 ID 를 기준으로 조회하는 것이다. 
```sql
select * from article
where id < 9985 and deleted = false
order by id desc
limit 10;
```
id 는 인덱스이므로 DB 는 9985 보다 작은 id 값인 9984를 바로 찾을 수 있다. 오프셋을 세는 시간이 생략되어 더 빠르다.

프런트엔드 개발자가 다음에 읽어올 데이터가 존재하는지 알려주는 속성을 응답 결과에 포함시켜 달라고 요청하면, 1개만 더 읽어 판단하면 된다. 

### 조회 범위를 시간 기준으로 제한하기
조회 성능을 개선하는 방법 중 하나는 조회 범위를 시간 기준으로 제한하는 것이다. 

조회 범위를 제한하는 또 다른 방법은 최신 데이터만 조회하는 것이다. 대부분의 기능은 최신 데이터를 주로 조회하기 때문이다. 최신 데이터 위주로 조회하게 기능을 변경하면 DB 성능 또한 향상된다. DB 는 성능을 높이기 위해 메모리 캐시를 사용한다. 데이터 조회가 발생하면 이를 메모리에 캐시해, 다음에 동일한 요청이 들어올 때 더 빠르게 응답할 수 있다.

### 전체 개수 세지 않기
데이터가 적을 때는 count 쿼리를 실행해도 큰 문제가 없다. 문제는 데이터가 급격히 증가하기 시작할 때 발생한다. 데이터가 많아질수록 count 실행 시간도 증가하는데, 그 이유는 조건에 해당하는 모든 데이터들을 탐색해야 하기 때문이다. 

### 오래된 데이터 삭제 및 분리 보관하기
데이터 개수가 늘어나면 늘어날수록 쿼리 실행 시간은 증가한다. 즉, 데이터 개수가 증가하지 않으면 실행 시간을 일정 수준으로 유지할 수 있다. 또는 데이터 증가 속도를 늦추면, 실행 시간 증가 폭을 줄일 수 있다.

## 알아두면 좋을 몇 가지 주의 사항
### 상태 변경 기능은 복제 DB 에서 조회하지 않기
Primary DB - Replica DB 구조를 사용할 때 변경은 주 DB 를 사용하고 조회는 복제 DB 를 사용한다. 그런데 이를 잘못 이해해 모든 `SELECT` 쿼리를 무조건 복제 DB 에서 실행하는 경우가 있다.
이는 두 가지 측면에서 문제를 일으킬 수 있다.
1. 주 DB 와 복제 DB 는 순간적으로 데이터가 일치하지 않을 수 있다. 주 DB 에서 변경된 데이터는 다음 두 단계를 거쳐 복제 DB에 반영된다.
	- 네트워크를 통해 복제 DB 에 전달
	- 복제 DB 는 자체 데이터에 변경 내용을 반영
이 과정에는 시간이 걸린다. 주 DB 에서 복제 DB 로의 데이터 복제에는 지연이 발생한다. 이 지연 시간만큼 주 DB 와 복제 DB 는 일시적으로 서로 다른 값을 갖게 된다.
![[Screenshot 2025-10-26 at 19.42.45.png]]
2. 트랜잭션 문제가 발생할 수 있다. 주 DB 와 복제 DB 간 데이터 복제는 트랜잭션 커밋 시점에 이뤄진다. 주 DB 의 트랜잭션 범위 내에서 데이터를 변경하고 복제 DB 에서 변경 대상이 될 수 있는 데이터를 조회하면 데이터 불일치로 인해 문제가 생긴다.
회원 가입, 변경, 등록, 삭제와 같이 `INSERT`, `UPDATE`, `DELETE` 쿼리를 실행하는 기능에서 변경 대상 데이터를 조회해야 한다면, 복제 DB 가 아닌 `INSERT`, `UPDATE`, `DELETE` 쿼리를 실행하는 주 DB에서 `SELECT` 쿼리를 실행하자. 그래야 데이터 불일치로 인해 발생할 수 있는 오류를 방지할 수 있다.

### 배치 쿼리 실행 시간 증가
배치에서 사용하는 쿼리의 실행시간을 지속적으로 추적해야 한다. 추적을 통해 쿼리 실행 시간이 갑자기 큰 폭으로  증가했는지를 감지할 수 있고, 문제가 되는 쿼리를 발견하면 원인을 찾아 해결할 수 있다.

해결 방법으로는 이하의 것들이 있다.
- DB 장비의 사양을 높이기
- [[커버링 인덱스]] 활용하기
- 데이터를 일정 크기로 나눠 처리하기
집계 쿼리는 특성상 많은 데이터를 스캔한다. 이때 집계 대상 컬럼이 인덱스에 포함되어 있다면, 데이터를 직접 읽지 않고 인덱스만 스캔해 집계를 수행할 수 있다. 커버링 인덱스를 활용하면 처리 속도는 빨라지고 DB 가 사용하는 메모리도 줄어든다.
![[Screenshot 2025-10-26 at 19.58.12.png]]

### 타입이 다른 컬럼 조인 주의
타입이 다른 컬럼끼리 조인시에는 DB가 서로 다른 타입간의 타입 변환이 일어난다. 이 변환은 각 행마다 발생하며 인덱스를 온전히 활용하지 못할 가능성이 높다.

### 테이블 변경은 신중하게
데이터가 많은 테이블에 새로운 컬럼을 추가하거나 기존 열거 타입 컬럼을 변경할 때는 매우 주의해야 한다. 
테이블 변경 시 주의해야 하는 이유는 DB 의 테이블 변경 방식 때문이다. 예를 들어 MySQL 은 테이블을 변경할 때 새 테이블을 생성하고 원본 테이블의 데이터를 복사한 뒤, 복사가 완료되면 새 테이블로 대체한다. 이 복사 과정에서는 `UPDATE`, `INSERT`, `DELETE` 같은 DML 작업을 허용하지 않기 떄문에 복사 시간만큼 서비스가 멈춘다.

DML을 허용하면서 테이블을 변경하는 기능도 있지만 항상 가능한 것은 아니다. 그래서 데이터가 많은 테이블은 점검 시간을 잡고 변경하는 경우가 많다. 서비스를 잠시 중단한 뒤 변경 작업을 수행하는 것이 가장 안정적이기 때문이다.

### DB 최대 연결 개수
DB 서버 자원에는 여유가 있지만 API 서버에서 DB 에 연결되지 않는다면 DB 에 설정된 최대 연결 개수를 확인해야한다.

예를들어 DB의 최대 연결 개수가 100개로 설정되어 있다고 하자. API 서버의 커넥션 풀 개수가 30개일 때 API 서버를 네 대로 늘리면 필요한 커넥션 수는 120개다. 하지만 DB는 100개까지만 연결을 허용하므로 20개의 커넥션을 얻지 못하고 연결 실패가 발생하게 된다. 이 경우에는 DB의 최대 연결 개수를 늘려주는 것만으로도 문제를 해결할 수 있다.

단, DB 서버의 CPU 사용률이 70% 이상으로 높다면 연결 개수를 늘리면 안된다.

## 실패와 트랜잭션 고려하기
서버 초심자가 자주 놓치는 것 중 하나는 DB 트랜잭션을 고려하지 않는 것이다. 모든 코드가 항상 정상적으로 동작하는 것은 아니기 때문에 비정상 상황에서의 트랜잭션 처리를 반드시 고민해야 한다. 트랜잭션을 고려하지 않고 코드를 작성하면 데이터 일관성에 문제가 생길 수 있다.

자주 발생하는 실수 중 하나는 트랜잭션 없이 여러 데이터를 수정하는 것이다. DB 관련 코드를 작성할 때는 트랜잭션의 시작과 종료 경계를 명확히 설정했는지 반드시 확인해야 한다.

보통은 일부 기능에서 오류가 발생하면 전체 트랜잭션을 롤백한다. 하지만 경우에 따라 일부 기능에서 오류가 나도 트랜잭션을 커밋해야 할 상황도 있다. 이런 경우들은 오류를 로그로 기록해 모니터링 하는 방식을 사용해야 한다.
- ex) 회원가입시 메일 송신기능: 회원가입은 성공했지만 메일 송신에서 실패했다고 전체 실패로 할 필요는 없다

외부 API 연동과 DB 작업이 섞이면 트랜잭션 처리가 복잡해진다. 외부 API 호출은 성공했지만 DB 작업이 실패하는 상황이 대표적이다.



